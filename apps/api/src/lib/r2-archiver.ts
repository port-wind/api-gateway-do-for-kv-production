/**
 * R2 å½’æ¡£ç®¡ç†
 * 
 * åˆ†å±‚å½’æ¡£ç­–ç•¥ï¼š
 * - traffic_eventsï¼ˆæ˜ç»†è¡¨ï¼‰ï¼š
 *   - çƒ­æ•°æ®ï¼ˆ0-3 å¤©ï¼‰ï¼šä¿ç•™åœ¨ D1
 *   - æ¸©æ•°æ®ï¼ˆ3-30 å¤©ï¼‰ï¼šå½’æ¡£åˆ° R2
 *   - å†·æ•°æ®ï¼ˆ>30 å¤©ï¼‰ï¼šç»§ç»­ä¿ç•™åœ¨ R2 æˆ–åˆ é™¤
 * 
 * - path_stats_hourlyï¼ˆèšåˆè¡¨ï¼‰ï¼š
 *   - æ‰€æœ‰å†å²æ•°æ®ï¼šæ°¸ä¹…ä¿ç•™åœ¨ D1 âœ…
 */

import type { Env } from '../types/env';

/**
 * å½’æ¡£é…ç½®
 */
export const ARCHIVE_CONFIG = {
    // å½’æ¡£é˜ˆå€¼ï¼š3 å¤©å‰çš„æ•°æ®
    ARCHIVE_DAYS_AGO: 3,
    // æ¯æ‰¹è¯»å–çš„è®°å½•æ•°
    BATCH_SIZE: 5000,
    // å‹ç¼©æ ¼å¼
    COMPRESSION: 'gzip' as const,
    // R2 è·¯å¾„å‰ç¼€
    R2_PREFIX: 'traffic-events',
};

/**
 * å½’æ¡£ä»»åŠ¡ç»“æœ
 */
export interface ArchiveResult {
    date: string;              // å½’æ¡£æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
    recordCount: number;       // å½’æ¡£è®°å½•æ•°
    fileSizeBytes: number;     // æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    r2Path: string;            // R2 å­˜å‚¨è·¯å¾„
    duration: number;          // å½’æ¡£è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    status: 'success' | 'failed';
    error?: string;
}

/**
 * è·å–éœ€è¦å½’æ¡£çš„æ—¥æœŸåˆ—è¡¨
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param daysAgo å½’æ¡£ N å¤©å‰çš„æ•°æ®
 * @returns Promise<string[]> æ—¥æœŸåˆ—è¡¨ï¼ˆYYYY-MM-DDï¼‰
 */
export async function getDatesToArchive(
    env: Env,
    daysAgo: number = ARCHIVE_CONFIG.ARCHIVE_DAYS_AGO
): Promise<string[]> {
    console.log(`ğŸ“… æŸ¥æ‰¾éœ€è¦å½’æ¡£çš„æ—¥æœŸï¼ˆ${daysAgo} å¤©å‰ï¼‰`);

    // è®¡ç®—ç›®æ ‡æ—¥æœŸ
    const targetDate = new Date();
    targetDate.setDate(targetDate.getDate() - daysAgo);
    const targetDateStr = targetDate.toISOString().split('T')[0];

    // æŸ¥è¯¢è¯¥æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®ä¸”æœªå½’æ¡£
    const result = await env.D1.prepare(
        `SELECT DISTINCT event_date 
     FROM traffic_events 
     WHERE event_date <= ? 
       AND event_date NOT IN (
         SELECT date FROM archive_metadata WHERE status = 'completed'
       )
     ORDER BY event_date`
    ).bind(targetDateStr).all();

    const dates = result.results?.map(row => row.event_date as string) || [];
    console.log(`âœ… æ‰¾åˆ° ${dates.length} ä¸ªå¾…å½’æ¡£æ—¥æœŸ: ${dates.join(', ')}`);

    return dates;
}

/**
 * å½’æ¡£æŒ‡å®šæ—¥æœŸçš„æ˜ç»†äº‹ä»¶åˆ° R2
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param date æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
 * @returns Promise<ArchiveResult>
 */
export async function archiveEventsForDate(
    env: Env,
    date: string
): Promise<ArchiveResult> {
    const startTime = Date.now();
    console.log(`========================================`);
    console.log(`ğŸ“¦ å¼€å§‹å½’æ¡£: ${date}`);
    console.log(`========================================`);

    try {
        // Step 1: åˆ›å»ºå½’æ¡£å…ƒæ•°æ®è®°å½•ï¼ˆçŠ¶æ€ï¼špendingï¼‰
        await createArchiveMetadata(env, date, 'pending');

        // Step 2: ç»Ÿè®¡è®°å½•æ•°ï¼ˆé¿å…åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼‰
        const countResult = await env.D1.prepare(
            `SELECT COUNT(*) as count FROM traffic_events WHERE event_date = ?`
        ).bind(date).first();

        const recordCount = (countResult?.count as number) || 0;

        if (recordCount === 0) {
            console.log(`âš ï¸ è¯¥æ—¥æœŸæ— æ•°æ®: ${date}`);
            await updateArchiveMetadata(env, date, 'completed', 0, 0, '');
            return {
                date,
                recordCount: 0,
                fileSizeBytes: 0,
                r2Path: '',
                duration: Date.now() - startTime,
                status: 'success'
            };
        }

        console.log(`ğŸ“Š å‘ç° ${recordCount} æ¡äº‹ä»¶`);

        // Step 3: æµå¼å‹ç¼©å¹¶ä¸Šä¼ åˆ° R2ï¼ˆé¿å… OOMï¼‰
        const r2Path = `${ARCHIVE_CONFIG.R2_PREFIX}/${date}.jsonl.gz`;
        const compressedSize = await streamEventsToR2(env, date, r2Path);

        console.log(`â˜ï¸ ä¸Šä¼ åˆ° R2: ${r2Path}`);
        console.log(`ğŸ—œï¸ å‹ç¼©åå¤§å°: ${formatBytes(compressedSize)}`);

        // Step 4: æ›´æ–°å½’æ¡£å…ƒæ•°æ®ï¼ˆçŠ¶æ€ï¼šcompletedï¼‰
        await updateArchiveMetadata(env, date, 'completed', recordCount, compressedSize, r2Path);

        const duration = Date.now() - startTime;
        console.log(`========================================`);
        console.log(`âœ… å½’æ¡£å®Œæˆ: ${date}`);
        console.log(`   è®°å½•æ•°: ${recordCount}`);
        console.log(`   æ–‡ä»¶å¤§å°: ${formatBytes(compressedSize)}`);
        console.log(`   è€—æ—¶: ${duration}ms`);
        console.log(`========================================\n`);

        return {
            date,
            recordCount,
            fileSizeBytes: compressedSize,
            r2Path,
            duration,
            status: 'success'
        };

    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        console.error(`âŒ å½’æ¡£å¤±è´¥: ${date}`, error);

        // æ›´æ–°å½’æ¡£å…ƒæ•°æ®ï¼ˆçŠ¶æ€ï¼šfailedï¼‰
        await updateArchiveMetadata(env, date, 'failed', 0, 0, '', errorMessage);

        return {
            date,
            recordCount: 0,
            fileSizeBytes: 0,
            r2Path: '',
            duration: Date.now() - startTime,
            status: 'failed',
            error: errorMessage
        };
    }
}

/**
 * æµå¼å¤„ç†ï¼šä» D1 è¯»å– â†’ å‹ç¼© â†’ ä¸Šä¼ åˆ° R2
 * 
 * âš ï¸ å…³é”®ï¼šåˆ†æ‰¹è¯»å–ã€è¾¹è¯»è¾¹å‹ç¼©ã€è¾¹å‹ç¼©è¾¹ä¸Šä¼ ï¼Œé¿å… OOM
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param date æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
 * @param r2Path R2 å­˜å‚¨è·¯å¾„
 * @returns Promise<number> å‹ç¼©åçš„æ–‡ä»¶å¤§å°
 */
async function streamEventsToR2(
    env: Env,
    date: string,
    r2Path: string
): Promise<number> {
    console.log(`ğŸŒŠ å¼€å§‹æµå¼å½’æ¡£: ${date}`);

    let offset = 0;
    let totalProcessed = 0;

    // åˆ›å»ºå‹ç¼©æµ
    const { readable, writable } = new TransformStream();
    const compressionStream = readable.pipeThrough(new CompressionStream('gzip'));
    const writer = writable.getWriter();
    const encoder = new TextEncoder();

    // å¼‚æ­¥è¯»å–å‹ç¼©åçš„æ•°æ®å—
    const compressedChunks: Uint8Array[] = [];
    const reader = compressionStream.getReader();
    const readCompressed = async () => {
        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            compressedChunks.push(value);
        }
    };
    const readPromise = readCompressed();

    // åˆ†æ‰¹è¯»å–å¹¶å†™å…¥å‹ç¼©æµ
    while (true) {
        const result = await env.D1.prepare(
            `SELECT * FROM traffic_events 
       WHERE event_date = ? 
       ORDER BY timestamp 
       LIMIT ? OFFSET ?`
        ).bind(date, ARCHIVE_CONFIG.BATCH_SIZE, offset).all();

        if (!result.results || result.results.length === 0) {
            break;
        }

        // è½¬æ¢ä¸º JSONL å¹¶å†™å…¥å‹ç¼©æµ
        for (const event of result.results) {
            const line = JSON.stringify(event) + '\n';
            await writer.write(encoder.encode(line));
        }

        totalProcessed += result.results.length;
        offset += ARCHIVE_CONFIG.BATCH_SIZE;

        console.log(`  å·²å¤„ç†: ${totalProcessed} æ¡`);

        // å¦‚æœè¯»å–çš„æ•°é‡å°‘äº BATCH_SIZEï¼Œè¯´æ˜å·²ç»è¯»å®Œ
        if (result.results.length < ARCHIVE_CONFIG.BATCH_SIZE) {
            break;
        }
    }

    // å…³é—­å†™å…¥æµ
    await writer.close();

    // ç­‰å¾…å‹ç¼©å®Œæˆ
    await readPromise;

    // åˆå¹¶æ‰€æœ‰å‹ç¼©å—
    const totalSize = compressedChunks.reduce((sum, chunk) => sum + chunk.length, 0);
    const compressed = new Uint8Array(totalSize);
    let position = 0;
    for (const chunk of compressedChunks) {
        compressed.set(chunk, position);
        position += chunk.length;
    }

    console.log(`ğŸ—œï¸ å‹ç¼©å®Œæˆ: ${totalProcessed} æ¡ â†’ ${formatBytes(compressed.byteLength)}`);

    // ä¸Šä¼ åˆ° R2
    await uploadToR2(env, r2Path, compressed.buffer);

    return compressed.byteLength;
}

/**
 * ä¸Šä¼ åˆ° R2
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param key R2 é”®
 * @param data æ•°æ®ï¼ˆArrayBufferï¼‰
 */
async function uploadToR2(env: Env, key: string, data: ArrayBuffer): Promise<void> {
    // æ£€æŸ¥ R2 ç»‘å®šæ˜¯å¦å­˜åœ¨
    if (!env.R2_ARCHIVE) {
        throw new Error('R2_ARCHIVE binding is not configured');
    }

    await env.R2_ARCHIVE.put(key, data, {
        httpMetadata: {
            contentType: 'application/gzip',
            contentEncoding: 'gzip'
        },
        customMetadata: {
            archived_at: new Date().toISOString(),
            source: 'traffic_events'
        }
    });
}

/**
 * åˆ›å»ºå½’æ¡£å…ƒæ•°æ®è®°å½•
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param date æ—¥æœŸ
 * @param status çŠ¶æ€
 */
async function createArchiveMetadata(
    env: Env,
    date: string,
    status: 'pending' | 'completed' | 'failed'
): Promise<void> {
    await env.D1.prepare(
        `INSERT OR REPLACE INTO archive_metadata 
     (date, r2_path, record_count, file_size_bytes, status, archived_at, d1_cleaned)
     VALUES (?, '', 0, 0, ?, ?, 0)`
    ).bind(date, status, Date.now()).run();
}

/**
 * æ›´æ–°å½’æ¡£å…ƒæ•°æ®è®°å½•
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param date æ—¥æœŸ
 * @param status çŠ¶æ€
 * @param recordCount è®°å½•æ•°
 * @param fileSizeBytes æ–‡ä»¶å¤§å°
 * @param r2Path R2 è·¯å¾„
 * @param errorMessage é”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
 */
async function updateArchiveMetadata(
    env: Env,
    date: string,
    status: 'pending' | 'completed' | 'failed',
    recordCount: number,
    fileSizeBytes: number,
    r2Path: string,
    errorMessage?: string
): Promise<void> {
    await env.D1.prepare(
        `UPDATE archive_metadata 
     SET r2_path = ?, 
         record_count = ?, 
         file_size_bytes = ?, 
         status = ?, 
         error_message = ?,
         completed_at = ?
     WHERE date = ?`
    ).bind(
        r2Path,
        recordCount,
        fileSizeBytes,
        status,
        errorMessage || null,
        status === 'completed' ? Date.now() : null,
        date
    ).run();
}

/**
 * ä» R2 è¯»å–å½’æ¡£æ•°æ®
 * 
 * @param env ç¯å¢ƒå˜é‡
 * @param date æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
 * @returns Promise<any[]> äº‹ä»¶æ•°ç»„
 */
export async function readArchiveFromR2(env: Env, date: string): Promise<any[]> {
    console.log(`ğŸ“¥ ä» R2 è¯»å–å½’æ¡£: ${date}`);

    if (!env.R2_ARCHIVE) {
        throw new Error('R2_ARCHIVE binding is not configured');
    }

    const r2Path = `${ARCHIVE_CONFIG.R2_PREFIX}/${date}.jsonl.gz`;
    const object = await env.R2_ARCHIVE.get(r2Path);

    if (!object) {
        throw new Error(`Archive not found: ${r2Path}`);
    }

    // è§£å‹ç¼©
    const compressedStream = object.body;
    const decompressedStream = compressedStream.pipeThrough(new DecompressionStream('gzip'));
    const text = await new Response(decompressedStream).text();

    // è§£æ JSONL
    const lines = text.trim().split('\n');
    const events = lines.map(line => JSON.parse(line));

    console.log(`âœ… è¯»å–åˆ° ${events.length} æ¡äº‹ä»¶`);
    return events;
}

/**
 * è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–å­—èŠ‚æ•°
 * 
 * @param bytes å­—èŠ‚æ•°
 * @returns æ ¼å¼åŒ–å­—ç¬¦ä¸²
 */
function formatBytes(bytes: number): string {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return Math.round((bytes / Math.pow(k, i)) * 100) / 100 + ' ' + sizes[i];
}

