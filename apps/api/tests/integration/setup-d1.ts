/**
 * é›†æˆæµ‹è¯• D1 æ•°æ®åº“åˆå§‹åŒ–è¾…åŠ©å·¥å…·
 * 
 * ç”¨æ³•ï¼š
 * ```typescript
 * import { initializeD1ForTests } from './setup-d1';
 * 
 * describe('My Integration Test', () => {
 *   initializeD1ForTests();  // è‡ªåŠ¨æ³¨å†Œ beforeAll å’Œ afterAll
 *   
 *   it('should work', async ({ env }) => {
 *     // env.D1 å·²åˆå§‹åŒ–å¹¶åŒ…å«æ‰€æœ‰è¡¨
 *   });
 * });
 * ```
 */

import { beforeAll, afterAll } from 'vitest';

let d1Initialized = false;
let migrationError: Error | null = null;

// D1 è¿ç§» SQLï¼ˆç›´æ¥åµŒå…¥ï¼Œé¿å…åœ¨ Workers ç¯å¢ƒä¸­ä½¿ç”¨ readFileSyncï¼‰
const MIGRATION_SQL = `
CREATE TABLE IF NOT EXISTS traffic_events (
  id TEXT PRIMARY KEY,
  path TEXT NOT NULL,
  method TEXT NOT NULL,
  status INTEGER NOT NULL DEFAULT 200,
  response_time REAL NOT NULL DEFAULT 0,
  client_ip_hash TEXT NOT NULL,
  user_agent TEXT,
  country TEXT,
  timestamp INTEGER NOT NULL,
  event_date TEXT NOT NULL,
  is_error INTEGER NOT NULL DEFAULT 0,
  created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_events_date ON traffic_events(event_date);
CREATE INDEX IF NOT EXISTS idx_events_path_date ON traffic_events(path, event_date);
CREATE INDEX IF NOT EXISTS idx_events_timestamp ON traffic_events(timestamp);
CREATE INDEX IF NOT EXISTS idx_events_id ON traffic_events(id);

CREATE TABLE IF NOT EXISTS path_stats_hourly (
  path TEXT NOT NULL,
  hour_bucket TEXT NOT NULL,
  requests INTEGER NOT NULL DEFAULT 0,
  errors INTEGER NOT NULL DEFAULT 0,
  sum_response_time REAL NOT NULL DEFAULT 0,
  count_response_time INTEGER NOT NULL DEFAULT 0,
  response_samples TEXT,
  ip_hashes TEXT,
  unique_ips_seen INTEGER NOT NULL DEFAULT 0,
  created_at INTEGER DEFAULT (strftime('%s', 'now')),
  updated_at INTEGER DEFAULT (strftime('%s', 'now')),
  PRIMARY KEY (path, hour_bucket)
);

CREATE INDEX IF NOT EXISTS idx_stats_hour ON path_stats_hourly(hour_bucket);
CREATE INDEX IF NOT EXISTS idx_stats_updated ON path_stats_hourly(updated_at);
CREATE INDEX IF NOT EXISTS idx_stats_requests ON path_stats_hourly(requests DESC);

CREATE TABLE IF NOT EXISTS archive_metadata (
  date TEXT PRIMARY KEY,
  r2_path TEXT NOT NULL,
  record_count INTEGER NOT NULL,
  file_size_bytes INTEGER,
  status TEXT NOT NULL DEFAULT 'pending',
  error_message TEXT,
  archived_at INTEGER NOT NULL,
  completed_at INTEGER,
  d1_cleaned INTEGER NOT NULL DEFAULT 0
);

CREATE INDEX IF NOT EXISTS idx_archive_status ON archive_metadata(status);
CREATE INDEX IF NOT EXISTS idx_archive_date ON archive_metadata(archived_at);

CREATE TABLE IF NOT EXISTS consumer_heartbeat (
  consumer_id TEXT PRIMARY KEY,
  last_heartbeat INTEGER NOT NULL,
  last_batch_size INTEGER,
  last_batch_duration_ms INTEGER,
  total_processed INTEGER NOT NULL DEFAULT 0,
  total_errors INTEGER NOT NULL DEFAULT 0,
  status TEXT NOT NULL DEFAULT 'active',
  updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);
`;

/**
 * æ³¨å†Œ D1 åˆå§‹åŒ–é’©å­
 * åœ¨æµ‹è¯•å¥—ä»¶å¼€å§‹å‰åˆå§‹åŒ– D1 è¡¨ç»“æ„
 */
export function initializeD1ForTests() {
    beforeAll(async () => {
        // åŠ¨æ€å¯¼å…¥ cloudflare:testï¼ˆåœ¨æµ‹è¯•è¿è¡Œæ—¶ç”± Vitest Workers Pool æä¾›ï¼‰
        // @ts-expect-error - cloudflare:test åœ¨æµ‹è¯•ç¯å¢ƒä¸­å¯ç”¨
        const { env } = await import('cloudflare:test');
        // è·³è¿‡å·²åˆå§‹åŒ–çš„æƒ…å†µ
        if (d1Initialized) {
            console.log('â­ï¸  D1 already initialized, skipping...');
            return;
        }

        // å¦‚æœä¹‹å‰åˆå§‹åŒ–å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯
        if (migrationError) {
            throw migrationError;
        }

        try {
            console.log('ğŸ”§ Initializing D1 database for integration tests...');

            // ä½¿ç”¨åµŒå…¥çš„ SQLï¼ˆé¿å… readFileSyncï¼‰
            const migrationSQL = MIGRATION_SQL;

            // å°† SQL åˆ†å‰²æˆå•ç‹¬çš„è¯­å¥
            const sqlStatements = migrationSQL
                .split(';')
                .map(s => s.trim())
                .filter(s => s.length > 0);

            // D1 batch é™åˆ¶ï¼šæœ€å¤š 10 æ¡è¯­å¥/æ‰¹æ¬¡ï¼Œéœ€è¦åˆ†æ‰¹æ‰§è¡Œ
            const BATCH_SIZE = 10;
            let totalExecuted = 0;

            for (let i = 0; i < sqlStatements.length; i += BATCH_SIZE) {
                const batch = sqlStatements
                    .slice(i, i + BATCH_SIZE)
                    .map(s => env.D1.prepare(s));

                await env.D1.batch(batch);
                totalExecuted += batch.length;
                console.log(`  âœ“ Batch ${Math.floor(i / BATCH_SIZE) + 1}: ${batch.length} statements`);
            }

            console.log(`âœ… D1 migrations executed: ${totalExecuted} statements`);

            // éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
            const tables = await env.D1.prepare(
                "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name"
            ).all();

            const tableNames = tables.results?.map((row: any) => row.name) || [];
            console.log(`ğŸ“Š D1 tables: ${tableNames.join(', ')}`);

            // éªŒè¯å¿…éœ€çš„è¡¨
            const requiredTables = ['traffic_events', 'path_stats_hourly', 'archive_metadata', 'consumer_heartbeat'];
            const missingTables = requiredTables.filter(table => !tableNames.includes(table));

            if (missingTables.length > 0) {
                throw new Error(`âŒ Missing required D1 tables: ${missingTables.join(', ')}`);
            }

            d1Initialized = true;
            console.log('âœ… D1 database initialized successfully');

        } catch (error) {
            migrationError = error as Error;
            console.error('âŒ D1 initialization failed:', error);
            throw error;
        }
    });

    afterAll(async () => {
        // åŠ¨æ€å¯¼å…¥ cloudflare:testï¼ˆåœ¨æµ‹è¯•è¿è¡Œæ—¶ç”± Vitest Workers Pool æä¾›ï¼‰
        // @ts-expect-error - cloudflare:test åœ¨æµ‹è¯•ç¯å¢ƒä¸­å¯ç”¨
        const { env } = await import('cloudflare:test');

        // å¯é€‰ï¼šæ¸…ç†æµ‹è¯•æ•°æ®
        // æ³¨æ„ï¼šæ¯ä¸ªæµ‹è¯•æ–‡ä»¶è¿è¡Œåœ¨éš”ç¦»çš„ç¯å¢ƒä¸­ï¼Œé€šå¸¸ä¸éœ€è¦æ¸…ç†
        try {
            console.log('ğŸ§¹ Cleaning up D1 test data...');
            await env.D1.batch([
                env.D1.prepare('DELETE FROM traffic_events'),
                env.D1.prepare('DELETE FROM path_stats_hourly'),
                env.D1.prepare('DELETE FROM archive_metadata'),
                env.D1.prepare('DELETE FROM consumer_heartbeat'),
            ]);
            console.log('âœ… D1 test data cleaned');
        } catch (error) {
            // é™é»˜å¤±è´¥ï¼Œæ¸…ç†ä¸æ˜¯å…³é”®æ“ä½œ
            console.warn('âš ï¸ D1 cleanup warning:', error);
        }
    });
}

/**
 * æ‰‹åŠ¨åˆå§‹åŒ– D1ï¼ˆç”¨äºé«˜çº§ç”¨ä¾‹ï¼‰
 * å¤§å¤šæ•°æƒ…å†µä¸‹åº”ä½¿ç”¨ initializeD1ForTests()
 */
export async function setupD1Manually(env: any): Promise<void> {
    await env.D1.exec(MIGRATION_SQL);
}

