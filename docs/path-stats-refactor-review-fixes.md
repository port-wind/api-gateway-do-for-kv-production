# è·¯å¾„ç»Ÿè®¡é‡æ„æ–¹æ¡ˆ - Review é—®é¢˜ä¿®æ­£æ€»ç»“

## æ–‡æ¡£ç‰ˆæœ¬
- **ä¿®æ­£æ—¥æœŸ**ï¼š2025-10-15
- **åŸºç¡€æ–‡æ¡£**ï¼š`docs/path-stats-refactor.md`
- **Review æ¥æº**ï¼šåŒäº‹æŠ€æœ¯å®¡æŸ¥

---

## ä¿®æ­£é—®é¢˜æ¸…å•

### âš ï¸ ç¬¬äºŒè½® Review æ–°å‘ç°é—®é¢˜

#### ğŸ”´ 6. Promise.allSettled é™é»˜ä¸¢å¤±å¤±è´¥æ¶ˆæ¯

**é—®é¢˜æè¿°**ï¼š  
ç¬¬ä¸€ç‰ˆä¿®æ­£ä½¿ç”¨ `Promise.allSettled` é¿å…å´©æºƒï¼Œä½†åç»­ä»å¯¹æ‰€æœ‰æ¶ˆæ¯æ‰§è¡Œ `msg.ack()`ï¼Œå¯¼è‡´éƒ¨åˆ† DO è°ƒç”¨å¤±è´¥æ—¶ï¼Œå¯¹åº”çš„äº‹ä»¶è¢«é™é»˜ä¸¢å¼ƒï¼Œé€ æˆ**æ•°æ®ä¸¢å¤±**ã€‚

**ä¿®æ­£æ–¹æ¡ˆ**ï¼ˆå·²å®æ–½ï¼‰ï¼š

```typescript
// è·Ÿè¸ªå¤±è´¥çš„ keyï¼Œé¿å…é™é»˜ä¸¢å¤±æ•°æ®
const failedKeys = new Set<string>();

for (let i = 0; i < groupEntries.length; i += CHUNK_SIZE) {
  const chunk = groupEntries.slice(i, i + CHUNK_SIZE);
  const promises = chunk.map(async ([key, events]) => {
    try {
      const response = await stub.fetch('/aggregate', { /* ... */ });
      if (!response.ok) {
        throw new Error(`DO è¿”å›é”™è¯¯çŠ¶æ€: ${response.status}`);
      }
      return { key, success: true };
    } catch (error) {
      console.error(`èšåˆå¤±è´¥ [${key}]:`, error);
      failedKeys.add(key);
      return { key, success: false, error };
    }
  });
  
  await Promise.allSettled(promises);
}

// é€‰æ‹©æ€§ç¡®è®¤æ¶ˆæ¯ï¼šåª ack æˆåŠŸçš„ï¼Œå¤±è´¥çš„ retry
if (failedKeys.size > 0) {
  for (const msg of batch.messages) {
    const event = msg.body;
    const key = `${event.path}:${getHourBucket(event.timestamp)}`;
    
    if (failedKeys.has(key)) {
      // é‡è¯•ï¼ˆå¸¦æŒ‡æ•°é€€é¿ï¼‰
      msg.retry({ delaySeconds: Math.min(60 * Math.pow(2, msg.attempts), 3600) });
    } else {
      msg.ack();
    }
  }
} else {
  // å…¨éƒ¨æˆåŠŸï¼Œæ‰¹é‡ç¡®è®¤
  for (const msg of batch.messages) {
    msg.ack();
  }
}
```

**å…³é”®æ”¹è¿›**ï¼š
- è·Ÿè¸ªæ¯ä¸ª DO è°ƒç”¨çš„æˆåŠŸ/å¤±è´¥çŠ¶æ€
- å¯¹å¤±è´¥çš„ key å¯¹åº”çš„æ¶ˆæ¯æ‰§è¡Œ `msg.retry()`ï¼ˆå¸¦æŒ‡æ•°é€€é¿ï¼‰
- åªå¯¹æˆåŠŸçš„æ¶ˆæ¯æ‰§è¡Œ `msg.ack()`
- å¤‡é€‰æ–¹æ¡ˆï¼šè‹¥å¤±è´¥ç‡ >10%ï¼ŒæŠ›å¼‚å¸¸æ‹’ç»æ•´æ‰¹æ¶ˆæ¯é‡æ–°æŠ•é€’

**æ¶‰åŠç« èŠ‚**ï¼š5.3ã€é™„å½• H Q9

---

#### ğŸ”´ 7. R2 å½’æ¡£ä»ç„¶å­˜åœ¨ OOM å’Œåˆ†ç‰‡å¤§å°é—®é¢˜

**é—®é¢˜æè¿°**ï¼š  
ç¬¬ä¸€ç‰ˆä¿®æ­£çš„ä¸¤ä¸ªå½’æ¡£æ–¹æ¡ˆå‡å­˜åœ¨è‡´å‘½ç¼ºé™·ï¼š

1. **Multipart æ–¹æ¡ˆ**ï¼š
   - BATCH_SIZE = 35000ï¼ˆçº¦ 5.3 MB gzip å‰ï¼‰
   - å‹ç¼©ç‡ 70-80%ï¼Œå‹ç¼©åçº¦ 1-1.5 MBï¼Œ**ä»ä½äº 5 MiB é™åˆ¶**
   - ä¼šå¯¼è‡´ `uploadPart` è¢« R2 æ‹’ç»

2. **å•æ¬¡ put() æ–¹æ¡ˆï¼ˆç¬¬ä¸€ç‰ˆï¼‰**ï¼š
   - åœ¨å†…å­˜ä¸­ç´¯ç§¯æ‰€æœ‰ chunksï¼š`chunks.push(jsonlData)`
   - 100 ä¸‡æ¡è®°å½•çº¦ 150 MBï¼ˆåŸå§‹æ•°æ®ï¼‰ï¼Œ**è¶…è¿‡ Workers 128 MB å†…å­˜é™åˆ¶**
   - ä¼šå¯¼è‡´ OOM é”™è¯¯

**ä¿®æ­£æ–¹æ¡ˆ**ï¼ˆå·²å½»åº•é‡æ„ï¼‰ï¼š

**æ–¹æ¡ˆ Aï¼šçœŸæ­£çš„æµå¼ä¸Šä¼ **ï¼ˆæ¨èç”¨äº <100 MB åœºæ™¯ï¼‰

```typescript
async function archiveWithSinglePut(env, dateStr, totalCount, archivePath) {
  const BATCH_SIZE = 5000; // é™ä½æ‰¹æ¬¡å¤§å°ï¼Œå‡å°‘å†…å­˜å³°å€¼
  let offset = 0;
  
  // åˆ›å»º ReadableStreamï¼ŒæŒ‰éœ€ä» D1 è¯»å–å¹¶å‹ç¼©
  const jsonlStream = new ReadableStream({
    async pull(controller) {
      if (offset >= totalCount) {
        controller.close();
        return;
      }
      
      const { results } = await env.D1.prepare(/* ... */)
        .bind(dateStr, BATCH_SIZE, offset).all();
      
      // é€è¡Œè¾“å‡º JSONLï¼Œç«‹å³é‡Šæ”¾å†…å­˜
      const jsonlChunk = results.map(r => JSON.stringify(r)).join('\n') + '\n';
      controller.enqueue(new TextEncoder().encode(jsonlChunk));
      
      offset += results.length;
    }
  });
  
  // æµå¼å‹ç¼©å¹¶ä¸Šä¼ ï¼ˆæ•°æ®ä¸åœ¨å†…å­˜ç´¯ç§¯ï¼‰
  const gzipStream = jsonlStream.pipeThrough(new CompressionStream('gzip'));
  await env.R2_BUCKET.put(archivePath, gzipStream, { /* metadata */ });
}
```

**å…³é”®ç‰¹æ€§**ï¼š
- ä½¿ç”¨ `ReadableStream` çš„ `pull()` æ–¹æ³•ï¼Œ**æŒ‰éœ€è¯»å–**æ•°æ®
- æ¯æ¬¡åªä¿ç•™å½“å‰æ‰¹æ¬¡ï¼ˆ5000 æ¡ï¼‰åœ¨å†…å­˜ä¸­
- é€šè¿‡ `pipeThrough(CompressionStream)` æµå¼å‹ç¼©
- **æ•°æ®ä¸åœ¨å†…å­˜ç´¯ç§¯**ï¼Œå†…å­˜å³°å€¼ä»…çº¦ 1 MB
- é€‚ç”¨åœºæ™¯ï¼š100 ä¸‡æ¡/æ—¥ â‰ˆ gzip å 30-45 MB

**æ–¹æ¡ˆ Bï¼šMultipart Upload + ç´¯ç§¯åˆ° 5 MiB å†å‘é€**ï¼ˆç”¨äº â‰¥100 MB åœºæ™¯ï¼‰

```typescript
async function archiveWithMultipart(env, dateStr, totalCount, archivePath) {
  const BATCH_SIZE = 5000;
  const MIN_PART_SIZE = 5 * 1024 * 1024; // 5 MiB
  
  let currentPartBuffer: Uint8Array[] = []; // å½“å‰åˆ†ç‰‡ç´¯ç§¯çš„æ•°æ®å—
  let currentPartSize = 0;
  let partNumber = 1;
  
  while (offset < totalCount) {
    // è¯»å–ä¸€æ‰¹æ•°æ®å¹¶å‹ç¼©
    const compressed = await compressGzipToUint8Array(jsonlData);
    
    // ç´¯ç§¯åˆ°å½“å‰åˆ†ç‰‡
    currentPartBuffer.push(compressed);
    currentPartSize += compressed.byteLength;
    
    // æ£€æŸ¥æ˜¯å¦è¾¾åˆ° 5 MiBï¼ˆæˆ–å·²æ˜¯æœ€åä¸€æ‰¹ï¼‰
    if (currentPartSize >= MIN_PART_SIZE || isLastBatch) {
      // åˆå¹¶ç¼“å†²åŒºå¹¶ä¸Šä¼ 
      const partData = concatenateUint8Arrays(currentPartBuffer);
      await multipartUpload.uploadPart(partNumber, partData);
      
      // æ¸…ç©ºç¼“å†²åŒºï¼Œé‡Šæ”¾å†…å­˜
      currentPartBuffer = [];
      currentPartSize = 0;
      partNumber++;
    }
  }
}
```

**å…³é”®ç‰¹æ€§**ï¼š
- åˆ†æ‰¹è¯»å– D1ï¼ˆ5000 æ¡/æ‰¹ï¼‰ï¼Œå‹ç¼©åç´¯ç§¯åˆ°ç¼“å†²åŒº
- **å½“ç´¯ç§¯å¤§å° â‰¥5 MiB æ—¶**æ‰ä¸Šä¼ ä¸ºä¸€ä¸ª part
- ä¸Šä¼ å**ç«‹å³æ¸…ç©ºç¼“å†²åŒº**ï¼Œé‡Šæ”¾å†…å­˜
- å†…å­˜å³°å€¼ï¼šå•ä¸ª part çš„å¤§å°ï¼ˆçº¦ 5-10 MBï¼‰ï¼Œå®‰å…¨åœ¨ 128 MB é™åˆ¶å†…
- ç¡®ä¿æ¯ä¸ª partï¼ˆé™¤æœ€åä¸€ä¸ªï¼‰â‰¥5 MiBï¼Œç¬¦åˆ R2 è¦æ±‚

**è‡ªåŠ¨å†³ç­–é€»è¾‘**ï¼š

```typescript
const estimatedSizeGzipMB = (totalCount * 150 * 0.25) / (1024 * 1024);

if (estimatedSizeGzipMB < 100) {
  // <100 MBï¼Œä½¿ç”¨å•æ¬¡ put() + çœŸæ­£çš„æµå¼è¯»å–
  await archiveWithSinglePut(env, dateStr, totalCount, archivePath);
} else {
  // â‰¥100 MBï¼Œä½¿ç”¨ Multipart Upload + ç´¯ç§¯åˆ° 5 MiB å†å‘é€
  await archiveWithMultipart(env, dateStr, totalCount, archivePath);
}
```

**æ¨èç­–ç•¥**ï¼š
- 100 ä¸‡æ¡/æ—¥ï¼ˆgzip å â‰ˆ30 MBï¼‰â†’ æ–¹æ¡ˆ A
- 400 ä¸‡æ¡/æ—¥+ï¼ˆgzip å â‰ˆ120 MBï¼‰â†’ æ–¹æ¡ˆ B

**æ¶‰åŠç« èŠ‚**ï¼šé™„å½• Gã€é™„å½• H Q10

---

#### ğŸ”´ 8. å½’æ¡£æˆåŠŸåæœªè°ƒç”¨æ¸…ç†é€»è¾‘

**é—®é¢˜æè¿°**ï¼š  
`archiveWithSinglePut` å’Œ `archiveWithMultipart` ä¸¤ä¸ªå‡½æ•°æˆåŠŸå®Œæˆä¸Šä¼ åï¼Œ**æ²¡æœ‰è°ƒç”¨ `finishArchive`**ï¼Œå¯¼è‡´ï¼š

1. **KV å…ƒæ•°æ®æœªå†™å…¥**ï¼šæ— æ³•æŸ¥è¯¢å½’æ¡£å†å²
2. **D1 è®°å½•æœªåˆ é™¤**ï¼šå·²å½’æ¡£æ•°æ®ä»å ç”¨ D1 ç©ºé—´ï¼Œ6-7 å¤©åä»ä¼šå¡«æ»¡æ•°æ®åº“
3. **ç›‘æ§æ•°æ®æœªå‘é€**ï¼šæ— æ³•è¿½è¸ªå½’æ¡£æˆåŠŸç‡å’Œæ•°æ®é‡
4. **å‡½æ•°ç­¾åé”™è¯¯**ï¼š`finishArchive` ç¼ºå°‘ `archivePath` å‚æ•°ï¼Œè¿è¡Œæ—¶ä¼šæŠ¥é”™

**ä¿®æ­£æ–¹æ¡ˆ**ï¼ˆå·²å®æ–½ï¼‰ï¼š

**1. ä¿®æ­£ `finishArchive` å‡½æ•°ç­¾å**ï¼š

```typescript
// âŒ é”™è¯¯ï¼ˆç¼ºå°‘ archivePath å‚æ•°ï¼‰
async function finishArchive(env: Env, dateStr: string, totalRecords: number) {
  // å‡½æ•°ä½“å†…ä½¿ç”¨ archivePathï¼Œä½†æœªå£°æ˜
  await env.KV.put(`archive:metadata:${dateStr}`, JSON.stringify({
    path: archivePath, // âŒ ReferenceError: archivePath is not defined
    // ...
  }));
}

// âœ… æ­£ç¡®
async function finishArchive(
  env: Env, 
  dateStr: string, 
  totalRecords: number, 
  archivePath: string // æ–°å¢å‚æ•°
) {
  await env.KV.put(`archive:metadata:${dateStr}`, JSON.stringify({
    path: archivePath, // âœ… ç°åœ¨å¯ä»¥è®¿é—®äº†
    // ...
  }));
  
  // åˆ é™¤ D1 ä¸­çš„è®°å½•
  // å‘é€ç›‘æ§æŒ‡æ ‡
}
```

**2. åœ¨ `archiveWithSinglePut` ä¸­è°ƒç”¨æ¸…ç†**ï¼š

```typescript
async function archiveWithSinglePut(/* ... */) {
  // ... æµå¼ä¸Šä¼ é€»è¾‘ ...
  
  await env.R2_BUCKET.put(archivePath, gzipStream, { /* ... */ });
  
  console.log(`å•æ¬¡ä¸Šä¼ å®Œæˆ: ${archivePath}, æ€»è®¡ ${totalRecords} æ¡è®°å½•`);
  
  // âœ… æ–°å¢ï¼šå½’æ¡£æˆåŠŸåæ‰§è¡Œæ¸…ç†å’Œå…ƒæ•°æ®è®°å½•
  await finishArchive(env, dateStr, totalRecords, archivePath);
}
```

**3. åœ¨ `archiveWithMultipart` ä¸­è°ƒç”¨æ¸…ç†**ï¼š

```typescript
async function archiveWithMultipart(/* ... */) {
  try {
    // ... Multipart ä¸Šä¼ é€»è¾‘ ...
    
    const completed = await multipartUpload.complete(uploadedParts);
    console.log(`Multipart ä¸Šä¼ å®Œæˆ: ${archivePath}, ...`);
    
    // âœ… æ–°å¢ï¼šå½’æ¡£æˆåŠŸåæ‰§è¡Œæ¸…ç†å’Œå…ƒæ•°æ®è®°å½•
    await finishArchive(env, dateStr, totalRecords, archivePath);
  } catch (error) {
    await multipartUpload.abort();
    throw error;
  }
}
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… ä¿®æ­£å‡½æ•°ç­¾åï¼Œæ·»åŠ ç¼ºå¤±çš„ `archivePath` å‚æ•°
- âœ… ä¸¤ä¸ªä¸Šä¼ è·¯å¾„éƒ½æ­£ç¡®è°ƒç”¨ `finishArchive`
- âœ… ç¡®ä¿å½’æ¡£æˆåŠŸåç«‹å³æ¸…ç† D1ï¼Œé‡Šæ”¾ç©ºé—´
- âœ… è®°å½•å½’æ¡£å…ƒæ•°æ®å’Œç›‘æ§æŒ‡æ ‡

**å½±å“**ï¼š
- **æœªä¿®æ­£å‰**ï¼šD1 ä¼šåœ¨ 6-7 å¤©å¡«æ»¡ï¼Œå¯¼è‡´æ•´ä¸ªç³»ç»Ÿå´©æºƒ
- **ä¿®æ­£å**ï¼šD1 å§‹ç»ˆä¿æŒ 3 å¤©æ•°æ®ï¼Œç©ºé—´ç¨³å®šåœ¨ ~450 MB

**æ¶‰åŠç« èŠ‚**ï¼šé™„å½• G

---

### âœ… 1. Workers 50 Subrequest é™åˆ¶é—®é¢˜

**é—®é¢˜æè¿°**ï¼š  
åŸæ–¹æ¡ˆåœ¨ Queue Consumer ä¸­ä½¿ç”¨ `Promise.all` è°ƒç”¨æ‰€æœ‰ (path, hour) å¯¹åº”çš„ DOï¼Œå½“æ‰¹æ¬¡åŒ…å« >50 ä¸ªä¸åŒç»„åˆæ—¶ä¼šè¶…å‡º Workers å•æ¬¡æ‰§è¡Œçš„ subrequest ä¸Šé™ï¼ˆ50 ä¸ªï¼‰ï¼Œå¯¼è‡´æ•´ä¸ªæ¶ˆè´¹è€…è°ƒç”¨å¤±è´¥ã€‚

**ä¿®æ­£æ–¹æ¡ˆ**ï¼š
```typescript
// åˆ†å—å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 45 ä¸ªï¼ˆç•™ 5 ä¸ªä½™é‡ç»™å…¶ä»–è¯·æ±‚ï¼‰
const CHUNK_SIZE = 45;
const groupEntries = Array.from(groups.entries());

for (let i = 0; i < groupEntries.length; i += CHUNK_SIZE) {
  const chunk = groupEntries.slice(i, i + CHUNK_SIZE);
  const promises = chunk.map(([key, events]) => {
    const doId = env.AGGREGATOR_DO.idFromName(key);
    const stub = env.AGGREGATOR_DO.get(doId);
    return stub.fetch('/aggregate', {
      method: 'POST',
      body: JSON.stringify(events)
    }).catch(error => {
      console.error(`èšåˆå¤±è´¥ [${key}]:`, error);
      return null; // å®¹é”™ï¼šå•ä¸ªå¤±è´¥ä¸å½±å“å…¶ä»–
    });
  });
  
  await Promise.allSettled(promises); // ä½¿ç”¨ allSettled å®¹é”™
}
```

**å¤‡é€‰æ–¹æ¡ˆ**ï¼š  
è‹¥æ‰¹æ¬¡ä¸­ key è¿‡å¤šï¼Œå¯æ”¹ä¸º"æ‰¹é‡èšåˆ DO"ï¼šå•ä¸ª DO æ¥æ”¶ `[{key, events}]` æ•°ç»„ï¼Œå†…éƒ¨å¾ªç¯å¤„ç†ï¼Œåªéœ€ 1 ä¸ª subrequestã€‚

**æ¶‰åŠç« èŠ‚**ï¼š5.3ã€é™„å½• H Q9

---

### âœ… 2. R2 Multipart Upload æœ€å°åˆ†ç‰‡å¤§å°é—®é¢˜

**é—®é¢˜æè¿°**ï¼š  
åŸæ–¹æ¡ˆ `BATCH_SIZE = 10000`ï¼ˆçº¦ 1.5 MBï¼‰è¿œä½äº R2/S3 è¦æ±‚çš„ **5 MiB æœ€å°åˆ†ç‰‡å¤§å°**ï¼ˆæœ€åä¸€ä¸ªåˆ†ç‰‡é™¤å¤–ï¼‰ï¼Œä¼šå¯¼è‡´ `uploadPart` å¤±è´¥ã€‚

**ä¿®æ­£æ–¹æ¡ˆ A**ï¼ˆå·²å®æ–½ï¼‰ï¼š
```typescript
const BATCH_SIZE = 35000; // çº¦ 5.3 MBï¼ˆgzip å‰ï¼‰
```

**âš ï¸ é—®é¢˜**ï¼šgzip å‹ç¼©ç‡çº¦ 70-80%ï¼Œå‹ç¼©åå¯èƒ½ä» <5 MiBã€‚

**ä¿®æ­£æ–¹æ¡ˆ Bï¼ˆæ¨èï¼‰**ï¼š
è‹¥å•æ—¥æ•°æ® <5 GiBï¼ˆçº¦ 3300 ä¸‡æ¡ï¼‰ï¼Œ**ç›´æ¥ä½¿ç”¨å•æ¬¡ `put()` è€Œé Multipart**ï¼š

```typescript
// åˆ†æ‰¹è¯»å– + æµå¼å‹ç¼©ä¸Šä¼ 
const chunks = [];
for (let i = 0; i < totalCount; i += 10000) {
  const { results } = await env.D1.prepare(/* ... */).all();
  chunks.push(results.map(r => JSON.stringify(r)).join('\n'));
}

const jsonlStream = new ReadableStream({
  start(controller) {
    for (const chunk of chunks) {
      controller.enqueue(new TextEncoder().encode(chunk + '\n'));
    }
    controller.close();
  }
});

const gzipStream = jsonlStream.pipeThrough(new CompressionStream('gzip'));
await env.R2_BUCKET.put(archivePath, gzipStream, { /* metadata */ });
```

**æ¨èç­–ç•¥**ï¼š
- 100 ä¸‡æ¡/æ—¥ â‰ˆ 150 MBï¼ˆåŸå§‹ï¼‰â†’ gzip åçº¦ 30-45 MB â†’ **é€‚åˆå•æ¬¡ `put()`**
- Phase 2~3 ä½¿ç”¨å•æ¬¡ `put()`
- Phase 5 è‹¥æ•°æ®é‡è¶… 5 GiB å†è¿ç§» Multipartï¼ˆBATCH_SIZE â‰¥50000ï¼‰

**æ¶‰åŠç« èŠ‚**ï¼šé™„å½• Gã€é™„å½• H Q10

---

### âœ… 3. D1 ä¸æ”¯æŒ DELETE ... LIMIT è¯­æ³•

**é—®é¢˜æè¿°**ï¼š  
D1 ä½¿ç”¨çš„ SQLite ç¼–è¯‘é…ç½®æœªå¯ç”¨ `SQLITE_ENABLE_UPDATE_DELETE_LIMIT` é€‰é¡¹ï¼Œç›´æ¥ä½¿ç”¨ `DELETE ... LIMIT` ä¼šæŠ¥è¯­æ³•é”™è¯¯ã€‚

**ä¿®æ­£æ–¹æ¡ˆ**ï¼š

```sql
-- âŒ é”™è¯¯ï¼ˆD1 ä¸æ”¯æŒï¼‰
DELETE FROM traffic_events WHERE event_date = ? LIMIT 5000;

-- âœ… æ­£ç¡®ï¼ˆä½¿ç”¨ rowid å­æŸ¥è¯¢ï¼‰
DELETE FROM traffic_events 
WHERE rowid IN (
  SELECT rowid FROM traffic_events 
  WHERE event_date = ? 
  LIMIT 5000
);
```

**æ€§èƒ½è€ƒé‡**ï¼š
- å­æŸ¥è¯¢å…ˆç”Ÿæˆä¸´æ—¶ç»“æœé›†ï¼ˆ5000 è¡Œï¼‰ï¼Œç„¶åæ‰¹é‡åˆ é™¤
- æ€§èƒ½ä¸ç›´æ¥ `DELETE LIMIT` åŸºæœ¬ç›¸åŒ
- éœ€ç¡®ä¿æœ‰ç´¢å¼•ï¼š`CREATE INDEX idx_events_date ON traffic_events(event_date)`

**æ¶‰åŠç« èŠ‚**ï¼šé™„å½• Gã€é™„å½• H Q11

---

### âœ… 4. KV åˆ·æ–°è®¡æ•°é€»è¾‘é”™è¯¯

**é—®é¢˜æè¿°**ï¼š  
åŸä»£ç åœ¨é€’å¢å‰åˆ¤æ–­ `updateCount % 10 === 0`ï¼Œå¯¼è‡´ï¼š
- ç¬¬ 1 æ¬¡æ›´æ–°ï¼š`updateCount = 0 â†’ 0 % 10 === 0 â†’ è§¦å‘åˆ·æ–°` âŒ
- ç¬¬ 10 æ¬¡æ›´æ–°ï¼š`updateCount = 9 â†’ 9 % 10 !== 0 â†’ ä¸åˆ·æ–°` âŒ

**ä¿®æ­£æ–¹æ¡ˆ**ï¼š

```typescript
// âŒ é”™è¯¯
const updateCount = (await storage.get('updateCount')) || 0;
await storage.put('updateCount', updateCount + 1);
if (updateCount % 10 === 0) { /* åˆ·æ–° */ }

// âœ… æ­£ç¡®
const updateCount = (await storage.get('updateCount')) || 0;
const nextCount = updateCount + 1;
await storage.put('updateCount', nextCount);
if (nextCount % 10 === 0) { /* åˆ·æ–° */ }
```

**é¢„æœŸè¡Œä¸º**ï¼š
- ç¬¬ 1~9 æ¬¡æ›´æ–°ï¼šä¸åˆ·æ–°
- ç¬¬ 10 æ¬¡æ›´æ–°ï¼šè§¦å‘åˆ·æ–° âœ…
- ç¬¬ 11~19 æ¬¡ï¼šä¸åˆ·æ–°
- ç¬¬ 20 æ¬¡ï¼šå†æ¬¡åˆ·æ–°

**æ¶‰åŠç« èŠ‚**ï¼š5.3ã€é™„å½• H Q12

---

### âœ… 5. npm åº“ Workers å…¼å®¹æ€§é£é™©

**é—®é¢˜æè¿°**ï¼š  
è®¸å¤šæµè¡Œçš„ t-digest/HLL npm åŒ…ä¾èµ– Node.js ç‰¹å®š APIï¼ˆå¦‚ `Buffer`ã€`fs`ã€`crypto` æ¨¡å—ï¼‰ï¼Œåœ¨ Workers è¿è¡Œæ—¶ä¼šå¤±è´¥ã€‚åŸæ–¹æ¡ˆå‡è®¾å¯ç›´æ¥ä½¿ç”¨è¿™äº›åº“ï¼Œä½†æœªåšå‰ç½®éªŒè¯ã€‚

**ä¿®æ­£æ–¹æ¡ˆ**ï¼š

#### Phase 0 å¿…é¡»å®Œæˆçš„éªŒè¯æ¸…å•

1. **å€™é€‰åº“è¯„ä¼°**ï¼š

   | åº“å | å…¼å®¹æ€§ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
   |------|-------|------|------|
   | `@observablehq/tdigest` | âœ… çº¯ ESM | æ— ä¾èµ–ã€ä½“ç§¯å° | åŠŸèƒ½è¾ƒç®€å• |
   | `tdigest` | âš ï¸ éœ€éªŒè¯ | åŠŸèƒ½å®Œæ•´ã€å‡†ç¡®åº¦é«˜ | å¯èƒ½ä¾èµ– Node Buffer |
   | `hyperloglog` | âš ï¸ éœ€éªŒè¯ | æ ‡å‡†å®ç° | éƒ¨åˆ†åŒ…ä¾èµ– Buffer |
   | WASM æ–¹æ¡ˆï¼ˆRustï¼‰ | âœ… Workers åŸç”Ÿæ”¯æŒ | æ€§èƒ½æœ€ä¼˜ | éœ€è‡ªè¡Œç¼–è¯‘ |

2. **éªŒè¯æ­¥éª¤**ï¼š
   ```typescript
   // åœ¨ Miniflare æˆ– wrangler dev ç¯å¢ƒæµ‹è¯•
   import TDigest from '@observablehq/tdigest';
   
   const td = new TDigest();
   for (let i = 0; i < 1000; i++) {
     td.push(Math.random() * 100);
   }
   
   // åºåˆ—åŒ–æµ‹è¯•
   const serialized = td.toJSON();
   const restored = TDigest.fromJSON(serialized);
   console.log('p95:', restored.percentile(0.95));
   
   // å­˜å‚¨åˆ° D1 æµ‹è¯•
   await env.D1.prepare('INSERT INTO test (data) VALUES (?)')
     .bind(JSON.stringify(serialized))
     .run();
   ```

3. **å…¼å®¹æ€§æ£€æŸ¥é¡¹**ï¼š
   - [ ] å¯¼å…¥æˆåŠŸï¼ˆæ—  `require()` æˆ– Node å†…ç½®æ¨¡å—ï¼‰
   - [ ] åºåˆ—åŒ–/ååºåˆ—åŒ–æ­£å¸¸
   - [ ] æ€§èƒ½è¾¾æ ‡ï¼ˆå¤„ç† 100 æ¡äº‹ä»¶ < 10msï¼‰
   - [ ] å†…å­˜å ç”¨åˆç†ï¼ˆ< 1 MB/å®ä¾‹ï¼‰
   - [ ] BLOB å­˜å‚¨åˆ° D1 åå¯æ­£ç¡®æ¢å¤

#### å¤‡é€‰æ–¹æ¡ˆï¼ˆè‹¥éªŒè¯å¤±è´¥ï¼‰

**ç®€åŒ–ç»Ÿè®¡**ï¼š
```typescript
// ä¸ä½¿ç”¨ t-digestï¼Œæ”¹ç”¨æ’åºæ•°ç»„è®¡ç®—ç™¾åˆ†ä½
const responseTimes = events.map(e => e.responseTime).sort((a, b) => a - b);
const p95Index = Math.floor(responseTimes.length * 0.95);
const p95 = responseTimes[p95Index];

// å­˜å‚¨é‡‡æ ·æ•°æ®ï¼ˆæœ€å¤šä¿ç•™ 1000 ä¸ªæ ·æœ¬ï¼‰
const samples = responseTimes.slice(0, 1000);
await env.D1.prepare('UPDATE path_stats_hourly SET response_samples = ?')
  .bind(JSON.stringify(samples))
  .run();
```

**Bloom Filter ä»£æ›¿ HLL**ï¼ˆunique IPï¼‰ï¼š
- Workers æœ‰çº¯ JS å®ç°çš„ Bloom Filterï¼ˆå¦‚ `bloom-filters`ï¼‰
- å‡†ç¡®åº¦ç•¥ä½ï¼ˆå¯èƒ½é«˜ä¼° 1-2%ï¼‰ï¼Œä½†è¶³å¤Ÿå®ç”¨

**æ¶‰åŠç« èŠ‚**ï¼š9ã€é™„å½• H Q13

---

## é£é™©ä¸ç¼“è§£æªæ–½æ›´æ–°

| é£é™© | ä¿®æ­£åçš„ç¼“è§£æªæ–½ |
|------|----------------|
| **å½’æ¡£ä»»åŠ¡ OOM** | **åˆ†æ‰¹æŸ¥è¯¢ï¼ˆLIMIT 35000ï¼Œgzip å‰ â‰¥5.3 MBï¼‰ï¼›æ¨èä½¿ç”¨å•æ¬¡ `put()` è€Œé Multipartï¼ˆ<5 GiB åœºæ™¯ï¼‰** |
| **Workers 50 subrequest é™åˆ¶** | **DO è°ƒç”¨åˆ†å—ï¼ˆâ‰¤45 ä¸ª/æ‰¹ï¼‰ï¼›ä½¿ç”¨ `Promise.allSettled` å®¹é”™ï¼›è¶…å¤§æ‰¹æ¬¡æ”¹ç”¨æ‰¹é‡èšåˆ DO** |
| **R2 åˆ†ç‰‡å¤§å°ä¸ç¬¦** | **æé«˜ BATCH_SIZE è‡³ â‰¥50000 æˆ–ä½¿ç”¨å•æ¬¡ `put()` æµå¼ä¸Šä¼ ** |
| **D1 DELETE LIMIT ä¸æ”¯æŒ** | **ä½¿ç”¨ `rowid` å­æŸ¥è¯¢ï¼š`DELETE WHERE rowid IN (SELECT ... LIMIT)`** |
| **npm åº“å…¼å®¹æ€§** | **Phase 0 éªŒè¯åº“å¯ç”¨æ€§ï¼›å¤±è´¥åˆ™é™çº§åˆ°ç®€åŒ–ç»Ÿè®¡ï¼ˆæ’åºæ•°ç»„ + Bloom Filterï¼‰** |

---

## å…³é”®å®æ–½æ£€æŸ¥æ¸…å•æ›´æ–°

### Phase 0 å‰ç½®éªŒè¯ï¼ˆæ–°å¢/ä¿®æ”¹ï¼‰

- [ ] **âš ï¸ å¿…åš**ï¼šéªŒè¯ Workers å…¼å®¹çš„ t-digest/HLL åº“
  - [ ] åœ¨ Miniflare ç¯å¢ƒæµ‹è¯•åºåˆ—åŒ–/ååºåˆ—åŒ–æ€§èƒ½ï¼ˆ< 10ms/æ‰¹ï¼‰
  - [ ] éªŒè¯æ—  Node.js Buffer/Stream ä¾èµ–
  - [ ] æµ‹è¯•å†…å­˜å ç”¨ï¼ˆå•ä¸ªå®ä¾‹ < 1 MBï¼‰
  - [ ] éªŒè¯ BLOB å­˜å‚¨åˆ° D1 åå¯æ­£ç¡®æ¢å¤
  - [ ] **è‹¥éªŒè¯å¤±è´¥ï¼Œå‡†å¤‡ç®€åŒ–ç»Ÿè®¡å¤‡é€‰æ–¹æ¡ˆ**

- [ ] éªŒè¯ R2 API å…¼å®¹æ€§
  - [ ] **æ¨è**ï¼šæµ‹è¯•å•æ¬¡ `put()` æµå¼ä¸Šä¼ ï¼ˆ<5 GiB åœºæ™¯ï¼‰
  - [ ] è‹¥ä½¿ç”¨ Multipartï¼Œç¡®ä¿åˆ†ç‰‡ â‰¥5 MiBï¼ˆBATCH_SIZE â‰¥50000ï¼‰

- [ ] å‡†å¤‡ DO èšåˆåè°ƒå™¨ä»£ç 
  - [ ] **å…³é”®**ï¼šéªŒè¯ 50 subrequest é™åˆ¶å¤„ç†ï¼ˆåˆ†å— â‰¤45 ä¸ª/æ‰¹ï¼‰
  - [ ] å®ç°å®¹é”™æœºåˆ¶ï¼ˆ`Promise.allSettled`ï¼‰

- [ ] éªŒè¯ D1 æ“ä½œ
  - [ ] æµ‹è¯• rowid å­æŸ¥è¯¢åˆ é™¤æ€§èƒ½ï¼ˆåˆ†æ‰¹ 5000 æ¡ï¼‰
  - [ ] ç¡®è®¤ç´¢å¼•ç­–ç•¥ï¼ˆ`event_date`ã€`path`ï¼‰

- [ ] æµ‹è¯• KV åˆ·æ–°è®¡æ•°é€»è¾‘
  - [ ] æ¨¡æ‹Ÿ 20 æ¬¡æ›´æ–°ï¼Œç¡®ä¿ç¬¬ 10ã€20 æ¬¡è§¦å‘åˆ·æ–°

---

## å®æ–½é¡ºåºå»ºè®®ï¼ˆå·²æ›´æ–°ï¼‰

### Phase 0ï¼ˆå‰ç½®éªŒè¯ï¼‰
1. **å…³é”®**ï¼šéªŒè¯ t-digest/HLL åº“å…¼å®¹æ€§ï¼ˆè§é™„å½• H Q13ï¼‰
2. éªŒè¯ R2 å•æ¬¡ `put()` æµå¼ä¸Šä¼ ï¼ˆæ¨èæ–¹æ¡ˆï¼‰
3. éªŒè¯ D1 rowid å­æŸ¥è¯¢åˆ é™¤
4. è®¾è®¡ D1 è¡¨ç»“æ„ä¸ç´¢å¼•ç­–ç•¥
5. ç¡®è®¤æ¶ˆè´¹è€…å¹¶å‘ç­–ç•¥ï¼ˆå•æ¶ˆè´¹è€… vs DO åè°ƒå™¨ï¼‰

### Phase 1ï¼ˆWorker ç›´æ¥å†™ Queueï¼‰
- Worker ç›´æ¥å†™ Queueï¼Œå®ç°å»é‡é€»è¾‘
- **é…ç½® `max_concurrency=1`** é¿å…å¹¶å‘å†²çª
- ä¿ç•™æ—§ DO ä½œå…œåº•è¯»è·¯å¾„

### Phase 2ï¼ˆAggregator + D1ï¼‰
- å¼€å‘ Aggregator Workerï¼ˆ**ä½¿ç”¨éªŒè¯é€šè¿‡çš„ç»Ÿè®¡åº“**ï¼‰
- å®ç°**å•æ¬¡ `put()` æµå¼å½’æ¡£**ï¼ˆæ¨èï¼‰æˆ–åˆ†æ‰¹å½’æ¡£ï¼ˆBATCH_SIZE â‰¥50000ï¼‰
- ä½¿ç”¨ **rowid å­æŸ¥è¯¢** åˆ†æ‰¹åˆ é™¤
- é…ç½®é˜Ÿåˆ—ç§¯å‹ç›‘æ§ä¸æ¶ˆè´¹è€…å¿ƒè·³æ£€æµ‹

### Phase 3ï¼ˆæ¥å£åˆ‡æ¢ï¼‰
- åˆ‡æ¢æ¥å£è¯»è·¯å¾„ï¼ˆCacheâ†’KVâ†’D1ï¼‰
- ç°åº¦éªŒè¯åä¸‹çº¿æ—§ DO
- å‹åŠ›æµ‹è¯•éªŒè¯å•æ¶ˆè´¹è€…ååé‡

### Phase 4ï¼ˆç›‘æ§å®Œå–„ï¼‰
- å®Œå–„ç›‘æ§å‘Šè­¦
- **è‹¥æµé‡è¶…è¿‡ 50 ä¸‡/æ—¥ï¼Œè¿ç§»åˆ° DO èšåˆåè°ƒå™¨**ï¼ˆä½¿ç”¨åˆ†å—é€»è¾‘ï¼‰

### Phase 5ï¼ˆä¼˜åŒ–æ‰©å±•ï¼‰
- è‹¥ t-digest/HLL åº“æ€§èƒ½ä¸è¶³ï¼Œè€ƒè™‘ WASM æ–¹æ¡ˆ
- è‹¥æ•°æ®é‡è¶… 5 GiBï¼Œè¿ç§»åˆ° Multipart Upload
- Analytics Engine é›†æˆã€å¤šåº“åˆ†ç‰‡

---

## åç»­è¡ŒåŠ¨å»ºè®®

### âš ï¸ ç´§æ€¥è¡ŒåŠ¨ï¼ˆæœ¬å‘¨å¿…å®Œæˆï¼‰

1. **æµ‹è¯•å½’æ¡£å®Œæ•´æµç¨‹**ï¼ˆé˜²æ­¢ D1 å®¹é‡è€—å°½ï¼Œæœ€é«˜ä¼˜å…ˆçº§ï¼‰
   - âœ… éªŒè¯ `finishArchive` åœ¨ä¸¤ä¸ªä¸Šä¼ è·¯å¾„éƒ½è¢«è°ƒç”¨
   - âœ… æ¨¡æ‹Ÿå½’æ¡£æˆåŠŸåœºæ™¯ï¼Œç¡®è®¤ D1 è®°å½•è¢«åˆ é™¤
   - âœ… éªŒè¯ KV å…ƒæ•°æ®æ­£ç¡®å†™å…¥
   - âœ… éªŒè¯ç›‘æ§æŒ‡æ ‡æ­£ç¡®å‘é€

2. **æµ‹è¯•é€‰æ‹©æ€§ ack/retry é€»è¾‘**ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼Œæœ€é«˜ä¼˜å…ˆçº§ï¼‰
   - æ¨¡æ‹Ÿéƒ¨åˆ† DO è°ƒç”¨å¤±è´¥åœºæ™¯
   - éªŒè¯å¤±è´¥æ¶ˆæ¯è¢«æ­£ç¡® retryï¼ŒæˆåŠŸæ¶ˆæ¯è¢« ack
   - ç¡®è®¤æ— é™é»˜ä¸¢å¤±æ•°æ®

3. **æµ‹è¯•çœŸæ­£çš„æµå¼å½’æ¡£**ï¼ˆé˜²æ­¢ OOMï¼Œæœ€é«˜ä¼˜å…ˆçº§ï¼‰
   - éªŒè¯æ–¹æ¡ˆ Aï¼ˆReadableStream pullï¼‰å†…å­˜å³°å€¼ <10 MB
   - éªŒè¯æ–¹æ¡ˆ Bï¼ˆç´¯ç§¯åˆ° 5 MiBï¼‰å•ä¸ª part â‰¥5 MiB
   - æ¨¡æ‹Ÿ 100 ä¸‡æ¡è®°å½•å½’æ¡£ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨

4. **éªŒè¯ `@observablehq/tdigest` åœ¨ Workers ä¸­çš„å…¼å®¹æ€§**
   - åœ¨ Miniflare ç¯å¢ƒæµ‹è¯•å¯¼å…¥ã€åºåˆ—åŒ–ã€æ€§èƒ½
   - è‹¥ä¸å…¼å®¹ï¼Œç«‹å³å®æ–½ç®€åŒ–ç»Ÿè®¡å¤‡é€‰æ–¹æ¡ˆ

5. æµ‹è¯• rowid å­æŸ¥è¯¢åˆ é™¤æ€§èƒ½

6. æ›´æ–° `wrangler.toml` é…ç½®æ¨¡æ¿ï¼ˆ`max_concurrency=1`ï¼‰

### çŸ­æœŸè¡ŒåŠ¨ï¼ˆ2 å‘¨å†…ï¼‰
1. å®Œæˆ Phase 0 æ‰€æœ‰éªŒè¯é¡¹
2. ç¼–å†™ DO èšåˆåè°ƒå™¨ä»£ç ï¼ˆå« 50 subrequest é™åˆ¶å¤„ç†ï¼‰
3. å‡†å¤‡ç›‘æ§å‘Šè­¦é…ç½®
4. ç¼–å†™å•å…ƒæµ‹è¯•è¦†ç›–å…³é”®é€»è¾‘

### é•¿æœŸè§„åˆ’ï¼ˆPhase 4+ï¼‰
1. è‹¥ç»Ÿè®¡åº“æ€§èƒ½ä¸è¶³ï¼Œç ”ç©¶ WASM æ–¹æ¡ˆ
2. è‹¥æµé‡æŒç»­å¢é•¿ï¼Œå‡†å¤‡ DO èšåˆåè°ƒå™¨åˆ‡æ¢
3. è‹¥æ•°æ®é‡è¶…é¢„æœŸï¼Œè¯„ä¼° Analytics Engine è¿ç§»

---

## ä¿®æ­£æ€»ç»“

| ä¿®æ­£é¡¹ | ä¸¥é‡ç¨‹åº¦ | ä¿®æ­£çŠ¶æ€ | æµ‹è¯•è¦æ±‚ |
|-------|---------|---------|---------|
| **å½’æ¡£æˆåŠŸåæœªè°ƒç”¨æ¸…ç†é€»è¾‘** | ğŸ”´ **æé«˜ï¼ˆD1 å®¹é‡è€—å°½ï¼‰** | âœ… å·²ä¿®æ­£ | **Phase 0 å¿…æµ‹** |
| **Promise.allSettled é™é»˜ä¸¢å¤±æ¶ˆæ¯** | ğŸ”´ **æé«˜ï¼ˆæ•°æ®ä¸¢å¤±ï¼‰** | âœ… å·²ä¿®æ­£ | **Phase 0 å¿…æµ‹** |
| **R2 å½’æ¡£ OOM + åˆ†ç‰‡å¤§å°é—®é¢˜** | ğŸ”´ **æé«˜ï¼ˆæœåŠ¡å´©æºƒï¼‰** | âœ… å·²å½»åº•é‡æ„ | **Phase 0 å¿…æµ‹** |
| Workers 50 subrequest é™åˆ¶ | ğŸ”´ é«˜ | âœ… å·²ä¿®æ­£ | Phase 0 éªŒè¯ |
| D1 DELETE LIMIT ä¸æ”¯æŒ | ğŸŸ¡ ä¸­ | âœ… å·²ä¿®æ­£ | Phase 0 éªŒè¯ |
| KV åˆ·æ–°è®¡æ•°é€»è¾‘é”™è¯¯ | ğŸŸ¡ ä¸­ | âœ… å·²ä¿®æ­£ | Phase 0 éªŒè¯ |
| npm åº“å…¼å®¹æ€§é£é™© | ğŸ”´ é«˜ | âœ… å·²è¡¥å……éªŒè¯æµç¨‹ | **Phase 0 å¿…åš** |

**æ‰€æœ‰ä¿®æ­£å‡å·²æ›´æ–°åˆ° `docs/path-stats-refactor.md` åŸæ–‡æ¡£ä¸­ã€‚**

---

---

## ç¬¬äºŒè½® Review å½±å“è¯„ä¼°

### å‘ç°çš„ä¸¥é‡æ€§

ç¬¬äºŒè½® review å‘ç°çš„**ä¸‰ä¸ª**é—®é¢˜å‡ä¸º**ç”Ÿäº§ç¯å¢ƒè‡´å‘½ç¼ºé™·**ï¼š

1. **Promise.allSettled é™é»˜ä¸¢å¤±æ¶ˆæ¯**ï¼š
   - **å½±å“**ï¼š**æ•°æ®ä¸¢å¤±**ï¼Œç»Ÿè®¡æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•æ¢å¤
   - **è§¦å‘æ¡ä»¶**ï¼šä»»ä½• DO ç¬æ—¶æ•…éšœï¼ˆç½‘ç»œæŠ–åŠ¨ã€å†…å­˜å‹åŠ›ç­‰ï¼‰
   - **åæœ**ï¼šç”¨æˆ·æ— æ³•å¯Ÿè§‰ï¼Œé™é»˜ä¸¢å¤±æ•°æ®ï¼ŒæŸå®³ç³»ç»Ÿå¯ä¿¡åº¦

2. **R2 å½’æ¡£ OOM**ï¼š
   - **å½±å“**ï¼š**Worker å´©æºƒ**ï¼Œå½’æ¡£ä»»åŠ¡å¤±è´¥ï¼ŒD1 å®¹é‡æŒç»­å¢é•¿
   - **è§¦å‘æ¡ä»¶**ï¼š100 ä¸‡æ¡/æ—¥æµé‡ï¼ˆè®¾è®¡ç›®æ ‡ï¼‰
   - **åæœ**ï¼šD1 å®¹é‡è€—å°½ï¼ˆ6-7 å¤©ï¼‰ï¼Œæ‰€æœ‰ç»Ÿè®¡åŠŸèƒ½åœæ­¢

3. **å½’æ¡£æˆåŠŸåæœªè°ƒç”¨æ¸…ç†é€»è¾‘**ï¼ˆç¬¬äºŒè½®è¡¥å……ï¼‰ï¼š
   - **å½±å“**ï¼š**D1 å®¹é‡æ— æ³•é‡Šæ”¾**ï¼Œå³ä½¿å½’æ¡£æˆåŠŸï¼Œæ—§æ•°æ®ä»å ç”¨ç©ºé—´
   - **è§¦å‘æ¡ä»¶**ï¼šå½’æ¡£ä»»åŠ¡æ­£å¸¸è¿è¡Œï¼ˆ100% è§¦å‘ï¼‰
   - **åæœ**ï¼šD1 åœ¨ 6-7 å¤©å¡«æ»¡ï¼Œç³»ç»Ÿå´©æºƒï¼›KV æ— å…ƒæ•°æ®ï¼Œæ— æ³•æŸ¥è¯¢å†å²å½’æ¡£

### ä¸ºä»€ä¹ˆç¬¬ä¸€è½®ä¿®æ­£æœªå‘ç°ï¼Ÿ

- ç¬¬ä¸€è½® review å…³æ³¨**æ¥å£é™åˆ¶**ï¼ˆsubrequest ä¸Šé™ã€API è¯­æ³•ï¼‰
- ç¬¬äºŒè½® review å…³æ³¨**è¿è¡Œæ—¶è¡Œä¸º**ï¼ˆå†…å­˜ç´¯ç§¯ã€é”™è¯¯å¤„ç†ï¼‰
- **æ•™è®­**ï¼šæŠ€æœ¯æ–¹æ¡ˆéœ€è¦**å¤šè½® review**ï¼Œä»ä¸åŒè§’åº¦éªŒè¯å¯è¡Œæ€§

### ä¿®æ­£åçš„ä¿¡å¿ƒç­‰çº§

| ç»´åº¦ | ç¬¬ä¸€ç‰ˆæ–¹æ¡ˆ | ç¬¬äºŒç‰ˆæ–¹æ¡ˆï¼ˆå½“å‰ï¼‰ | æå‡ |
|------|----------|----------------|------|
| æ•°æ®å¯é æ€§ | âš ï¸ ä½ï¼ˆä¼šä¸¢æ•°æ®ï¼‰ | âœ… é«˜ï¼ˆé€‰æ‹©æ€§ ackï¼‰ | æå¤§æå‡ |
| å†…å­˜å®‰å…¨æ€§ | âš ï¸ ä½ï¼ˆä¼š OOMï¼‰ | âœ… é«˜ï¼ˆçœŸæ­£æµå¼ï¼‰ | æå¤§æå‡ |
| API å…¼å®¹æ€§ | âœ… é«˜ | âœ… é«˜ | ä¿æŒ |
| å¯æµ‹è¯•æ€§ | ğŸŸ¡ ä¸­ | âœ… é«˜ | æå‡ |

**ç»“è®º**ï¼šç¬¬äºŒç‰ˆæ–¹æ¡ˆå·²è§£å†³æ‰€æœ‰å·²çŸ¥çš„è‡´å‘½ç¼ºé™·ï¼Œå¯è¿›å…¥ Phase 0 éªŒè¯é˜¶æ®µã€‚

---

## è‡´è°¢

æ„Ÿè°¢åŒäº‹**ä¸¤è½®**è¯¦ç»†ä¸”æ·±å…¥çš„ reviewï¼š

- **ç¬¬ä¸€è½®**ï¼šå‘ç°äº† 5 ä¸ªå…³é”®çš„å¹³å°é™åˆ¶é—®é¢˜ï¼ˆsubrequest ä¸Šé™ã€R2 åˆ†ç‰‡å¤§å°ã€SQL è¯­æ³•ç­‰ï¼‰
- **ç¬¬äºŒè½®**ï¼šå‘ç°äº† 3 ä¸ªè‡´å‘½çš„è¿è¡Œæ—¶ç¼ºé™·ï¼ˆæ•°æ®ä¸¢å¤±ã€OOM é£é™©ã€æ§åˆ¶æµç¼ºé™·ï¼‰

è¿™äº›é—®é¢˜è‹¥ä¸åœ¨ Phase 0 è§£å†³ï¼Œå°†åœ¨ç”Ÿäº§ç¯å¢ƒå¯¼è‡´**æ•°æ®ä¸¢å¤±**æˆ–**æœåŠ¡å´©æºƒ**ã€‚ç‰¹åˆ«æ˜¯**æ§åˆ¶æµç¼ºé™·**ï¼ˆå½’æ¡£åæœªæ¸…ç†ï¼‰ï¼Œå³ä½¿å…¶ä»–éƒ¨åˆ†éƒ½æ­£ç¡®å®ç°ï¼Œç³»ç»Ÿä»ä¼šåœ¨ 6-7 å¤©åå›  D1 å®¹é‡è€—å°½è€Œå´©æºƒã€‚

ä¿®æ­£åçš„æ–¹æ¡ˆå·²å……åˆ†è€ƒè™‘ï¼š
- âœ… Cloudflare Workers å¹³å°çš„**æ¥å£é™åˆ¶**
- âœ… è¿è¡Œæ—¶çš„**å†…å­˜ä¸å¹¶å‘çº¦æŸ**
- âœ… **å®Œæ•´çš„æ§åˆ¶æµ**ï¼ˆæˆåŠŸ/å¤±è´¥è·¯å¾„éƒ½æ­£ç¡®å¤„ç†ï¼‰

**å…³é”®æ•™è®­**ï¼š
1. æŠ€æœ¯æ–¹æ¡ˆéœ€è¦**è‡³å°‘ä¸¤è½® review**ï¼Œåˆ†åˆ«å…³æ³¨"èƒ½ä¸èƒ½åš"å’Œ"åšå¾—å¯¹ä¸å¯¹"ã€‚
2. **æ§åˆ¶æµéªŒè¯**åŒæ ·é‡è¦ï¼šå³ä½¿æ¯ä¸ªå‡½æ•°éƒ½æ­£ç¡®ï¼Œå¦‚æœæ²¡æœ‰æ­£ç¡®è°ƒç”¨ï¼Œç³»ç»Ÿä»ä¼šå¤±è´¥ã€‚
3. **ç¤ºä¾‹ä»£ç éœ€è¦ç±»å‹æ£€æŸ¥**ï¼šå‡½æ•°ç­¾åé”™è¯¯ï¼ˆå¦‚ç¼ºå°‘å‚æ•°ï¼‰åº”åœ¨ review é˜¶æ®µå‘ç°ã€‚

**å»ºè®®åç»­ review æ¸…å•**ï¼š
- [ ] æ¥å£é™åˆ¶ï¼ˆAPI è¯­æ³•ã€é…é¢ã€è¶…æ—¶ï¼‰
- [ ] è¿è¡Œæ—¶çº¦æŸï¼ˆå†…å­˜ã€å¹¶å‘ã€é”™è¯¯å¤„ç†ï¼‰
- [ ] **æ§åˆ¶æµå®Œæ•´æ€§**ï¼ˆæˆåŠŸ/å¤±è´¥è·¯å¾„ã€æ¸…ç†é€»è¾‘ã€çŠ¶æ€ä¸€è‡´æ€§ï¼‰
- [ ] ç±»å‹æ£€æŸ¥ï¼ˆå‚æ•°åŒ¹é…ã€è¿”å›å€¼ï¼‰

